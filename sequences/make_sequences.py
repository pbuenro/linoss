#!/usr/bin/env python3
"""make_sequences.py ‚Äì Generate 30‚Äëday miss‚Äëdistance tensors
===========================================================

Reads dates from the `available_dates.log` file (generated by
`fetch_tle.py`) and processes each one to generate Parquet tensors.

This version fixes the path to the shared data directory, allowing it
to correctly find the `available_dates.log` file.
"""
from __future__ import annotations

import math
import os
import random
from datetime import datetime, timedelta, timezone
from itertools import combinations
from pathlib import Path
from typing import Final, List, Tuple, Optional

import numpy as np
import polars as pl
import typer
from sgp4.api import Satrec, jday
from tqdm.auto import tqdm

app = typer.Typer(add_completion=False, help="Generate SGP4 training tensors from a log of available dates.")

# --- Path Configuration (Robust Version) ---
SCRIPT_DIR = Path(__file__).parent.resolve()
# FIX: Correct path to the root data directory
# Go up from 'sequences' -> 'collision_mvp' and then down to 'data'
RAW_DIR: Final[Path] = SCRIPT_DIR / ".." / "data"
LOG_FILE_PATH: Final[Path] = RAW_DIR / "available_dates.log"
OUT_DIR: Final[Path] = SCRIPT_DIR / "parquet"
OUT_DIR.mkdir(exist_ok=True)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _load_day(date: str) -> Optional[Tuple[pl.DataFrame, float, float]]:
    """Load TLE DataFrame and solar indices for a single date."""
    date_path = RAW_DIR / date.replace("-", "/")
    tle_path = date_path / f"tles_{date}.csv"
    idx_path = date_path / f"indices_{date}.csv"

    if not tle_path.exists() or not idx_path.exists():
        tqdm.write(f"‚ö†Ô∏è  Data for {date} not found. Skipping.")
        return None

    tle_df = pl.read_csv(tle_path)
    if tle_df.height == 0:
        tqdm.write(f"‚ÑπÔ∏è  TLE file for {date} is empty. Skipping.")
        return None
        
    idx_df = pl.read_csv(idx_path)

    def _safe_float(val: object) -> float:
        try: return float(val)
        except (ValueError, TypeError): return 0.0

    f107 = _safe_float(idx_df.select("F10_7").row(0)[0])
    kp   = _safe_float(idx_df.select("Kp").row(0)[0])

    return tle_df, f107, kp


def _sat_from_row(row: pl.Series) -> Satrec:
    return Satrec.twoline2rv(row["TLE_LINE1"], row["TLE_LINE2"])


def _shell_bounds(sat: Satrec) -> Optional[Tuple[float, float]]:
    if getattr(sat, "error", 0) > 0:
        tqdm.write(f"‚ö†Ô∏è  Skipping SAT {sat.satnum}: invalid TLE (err {sat.error})")
        return None
    jd, fr = sat.jdsatepoch, sat.jdsatepochF
    e, r, _ = sat.sgp4(jd, fr)
    if e != 0:
        tqdm.write(f"‚ö†Ô∏è  Skipping SAT {sat.satnum}: sgp4 error {e} at epoch")
        return None
    alt = math.sqrt(r[0] ** 2 + r[1] ** 2 + r[2] ** 2) - 6378.137
    return alt - 50.0, alt + 50.0


def _propagate_xyz(sat: Satrec, jd0: float, fr0: float) -> Optional[np.ndarray]:
    xyz = np.empty((720, 3), np.float32)
    for h in range(720):
        jd, fr = jd0, fr0 + h / 24.0
        e, r, _ = sat.sgp4(jd, fr)
        if e != 0:
            tqdm.write(f"‚ö†Ô∏è  sgp4 error {e} for SAT {sat.satnum} at hour {h}; skipping pair")
            return None
        xyz[h] = r
    return xyz


def _process_date(date: str, sample: Optional[int]) -> None:
    """Run the full processing pipeline for a single date string."""
    tqdm.write(f"\nüóìÔ∏è  Processing {date}")

    load_result = _load_day(date)
    if load_result is None:
        return
    tle_df, f107, kp = load_result
    tqdm.write(f"üõ∞Ô∏è  {len(tle_df):,} satellites loaded")

    tqdm.write("üîß  Building propagators & shells ‚Ä¶")
    tle_df = tle_df.with_columns([
        pl.struct(["TLE_LINE1", "TLE_LINE2"]).map_elements(_sat_from_row).alias("satrec")
    ])
    tle_df = tle_df.with_columns([
        pl.col("satrec").map_elements(_shell_bounds, return_dtype=pl.Object).alias("shell")
    ])
    tle_df = tle_df.filter(pl.col("shell").is_not_null())
    tqdm.write(f"  ‚Ä¶ done ({len(tle_df):,} valid sats)")

    tqdm.write("üîé  Generating overlapping pairs ‚Ä¶")
    shells = tle_df["shell"].to_list()
    pairs: List[Tuple[int, int]] = []
    for i, j in combinations(range(len(shells)), 2):
        low_i, hi_i = shells[i]
        low_j, hi_j = shells[j]
        if hi_i >= low_j and hi_j >= low_i:
            pairs.append((i, j))
    
    if sample is not None and sample < len(pairs):
        random.seed(0)
        pairs = random.sample(pairs, sample)
    tqdm.write(f"  ‚Ä¶ {len(pairs):,} pairs selected")

    dt_obj = datetime.fromisoformat(date + "T00:00:00")
    jd0, fr0 = jday(dt_obj.year, dt_obj.month, dt_obj.day, dt_obj.hour, dt_obj.minute, dt_obj.second)
    side = np.column_stack([np.full(720, f107, np.float32), np.full(720, kp, np.float32)])

    for idx_a, idx_b in tqdm(pairs, desc=f"Propagating {date}", unit="pair", leave=False):
        row_a, row_b = tle_df.row(idx_a, named=True), tle_df.row(idx_b, named=True)
        sat_a, sat_b = row_a["satrec"], row_b["satrec"]
        
        xyz_a = _propagate_xyz(sat_a, jd0, fr0)
        xyz_b = _propagate_xyz(sat_b, jd0, fr0)
        
        if xyz_a is None or xyz_b is None: continue

        delta = xyz_a - xyz_b
        tensor = np.hstack([delta, side])
        out_file = OUT_DIR / f"{sat_a.satnum}_{sat_b.satnum}.parquet"
        pl.DataFrame(tensor).write_parquet(out_file)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@app.command()
def main(
    all_available: bool = typer.Option(
        False, "--all",
        help="Process all dates in available_dates.log.",
        show_default=False,
    ),
    sample: int | None = typer.Option(
        None, "--sample",
        min=1,
        help="Randomly sample N pairs for each day.",
        show_default=False,
    ),
) -> None:
    """Generate Parquet tensors for all dates in the available_dates.log file."""

    if not all_available:
        typer.secho("‚ùå  This script now requires the --all flag to run.", fg=typer.colors.RED)
        raise typer.Exit(1)
        
    if not LOG_FILE_PATH.exists():
        typer.secho(f"‚ùå Log file not found at: {LOG_FILE_PATH}", fg=typer.colors.RED)
        typer.secho("   Run `fetch_tle.py` to generate it.", fg=typer.colors.YELLOW)
        raise typer.Exit(1)
        
    with LOG_FILE_PATH.open("r") as f:
        dates_to_process = [line.strip() for line in f if line.strip()]

    if not dates_to_process:
        typer.secho("‚ÑπÔ∏è  The available_dates.log file is empty. Nothing to process.", fg=typer.colors.YELLOW)
        raise typer.Exit()

    typer.secho(f"Found {len(dates_to_process)} dates to process from log file.", fg=typer.colors.CYAN)
    
    for date_str in dates_to_process:
        _process_date(date_str, sample=sample)
        
    typer.secho("\n‚úÖ  All available dates processed.", fg=typer.colors.GREEN)


if __name__ == "__main__":
    app()
